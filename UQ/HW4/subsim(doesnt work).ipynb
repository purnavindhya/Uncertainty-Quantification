{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# g(\\textbf{X}) = 4 sqrt{2} - X_1 - X_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of imtermediate steps , M = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the performance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performace_fn(x):\n",
    "    g = 4*np.sqrt(2) - x[0] - x[1]\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.1                     # percentile cutoff/ imtermediate failure probability\n",
    "n = 2                       # number of random variables\n",
    "N_samples = 1000            # number of samples per subset\n",
    "N_f = int(N_samples*p)      # number of samples in the failure region\n",
    "N_c = int(1/p)               # number of samples generated from each Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating P(F_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Monte Carlo to find P(F_1)\n",
    "\n",
    "# generate samples from the standard normal distribution\n",
    "np.random.seed(0)\n",
    "x_samples = np.random.normal(size=(n,N_samples))\n",
    "g_samples = performace_fn(x_samples).reshape(-1,1)\n",
    "pf1 = N_f/N_samples\n",
    "\n",
    "# sorting the samples in ascending order\n",
    "index, g_sort = zip(*sorted(enumerate(g_samples), key=itemgetter(1)))\n",
    "\n",
    "# check if failure is reached\n",
    "    # indicator function for g(X) <= 0\n",
    "I_samples = np.zeros((N_samples,1))\n",
    "I_samples[g_samples < 0] = 1\n",
    "g_th1 = g_sort[N_f - 1]                            # threshold value of g(X)\n",
    "if g_th1 <= 0:\n",
    "    print('Failure is reached in the first subset')\n",
    "    g_th1 = 0\n",
    "    pf1 = I_samples.sum()/N_samples\n",
    "\n",
    "g_x1 = g_samples[index[0:N_f], : ]\n",
    "x1 = x_samples[:, index[0:N_f]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_track = g_th1             # keeping track of final sample in the failure region\n",
    "N_subsets = 1               # number of subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagating chains in the subsequent failure regions\n",
    "Propagating all the Markov Chains sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/9mr1g0xj6mqf2jl8_cvr2lwc0000gn/T/ipykernel_24610/4173237853.py:47: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y[0] = y_sort[i]\n",
      "/var/folders/f6/9mr1g0xj6mqf2jl8_cvr2lwc0000gn/T/ipykernel_24610/4173237853.py:64: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y[k+1] = perf_val.reshape(-1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nDim = 2 # number of dimensions of the problem (number of random variables)\n",
    "p = 0.1 # intermediate failure probability\n",
    "N = 1000000 # number of samples per intermediate level\n",
    "burnin = 0 # burn-in for MCMC (modified Metropolis), 0 in the original subsim\n",
    "\n",
    "Nt = int(N*p); # number of seeds for the next level\n",
    "\n",
    "nj = np.zeros((nDim,1))\n",
    "no_calls = 0 # number of performance function calls\n",
    "\n",
    "no_rep = 1 # how many independent subsim runs?\n",
    "for count in range(0,no_rep):\n",
    "    L = 1 \n",
    "    nf = 0\n",
    "    x = np.random.randn(nDim,N)\n",
    "    y = performace_fn(x) # PERFORMANCE FUNCTION \n",
    "    y = y.reshape(-1,1)\n",
    "# % G(x) should be able to take N number of nDim-dimensional samples in the \n",
    "# % form of a nDim x N matrix (the matrix x above) and output N performance \n",
    "# % function values. If it cannot, i.e. performance function can only take as\n",
    "# % input one nDim-dimensional sample and output one number, loop the above st-\n",
    "# % atement N times for each sample in the matrix x (which is nDim x N) so that\n",
    "# % y ultimately is a vector of N values.\n",
    "    # nf = []\n",
    "    # nf.append(None)\n",
    "    no_calls = no_calls + N\n",
    "    pf = []\n",
    "    while nf/N < p: # loop until the failure region has at least Nt samples, i.e. intermediate threshold value lies in the failure region\n",
    "        L = L + 1\n",
    "        ind, y_sort = zip(*sorted(enumerate(y), key=itemgetter(1)))\n",
    "        # [y_sort,ind] = np.argsort(y,'ascend')\n",
    "        y_sort = np.array(y_sort)[1:Nt].reshape(-1,1)\n",
    "        # print(y_sort.shape)\n",
    "        # print(L)\n",
    "\n",
    "        yL = y_sort[-1]\n",
    "        x_sort = x[:,ind[0:Nt]]\n",
    "        \n",
    "        mc = np.zeros((nDim, int(1/p) , Nt))\n",
    "        x = np.zeros((nDim,N))\n",
    "        y_s = np.zeros(N)\n",
    "        cont = 1\n",
    "        for i in range(0,Nt-1): # loop for each seed in the intermediate failure region\n",
    "            y = np.ones(int(1/p) + burnin)\n",
    "            mc[:,1,i] = x_sort[:,i]\n",
    "            for k in range(0,int(1/p) + burnin - 1): # each chain originating from a seed has length (1/p - 1); burnin = 0\n",
    "                y[0] = y_sort[i]\n",
    "                nj = mc[:,k,i].reshape(-1,1)\n",
    "                prop = nj + np.random.randn(nDim,1)\n",
    "                met_ratio = np.random.normal(prop)/np.random.normal(mc[:,k,i])\n",
    "                met_satis = 1*(np.random.rand(nDim,1)<met_ratio)\n",
    "                mc[met_satis, k+1, i] = prop[met_satis].squeeze()\n",
    "                nj[met_satis] = prop[met_satis]\n",
    "                \n",
    "                if (met_satis==np.zeros((nDim,1))).all(): ## ALL OF THE METROPOLIS CONDITIONS?\n",
    "                    perf_val = y[k]\n",
    "                else:\n",
    "                    no_calls = no_calls + 1\n",
    "                    perf_val = performace_fn(nj) #PERFORMANCE FUNCTION\n",
    "                \n",
    "                \n",
    "                if (perf_val<yL).any(): ## ANY OF THE PERF VALUES?\n",
    "                    mc[:,k+1,i] = nj.squeeze()\n",
    "                    y[k+1] = perf_val.reshape(-1)\n",
    "                else:\n",
    "                    mc[:,k+1,i] = mc[:,k,i]\n",
    "                    y[k+1] = y[k]\n",
    "                \n",
    "            cont_end = cont + int(1/p) - 1\n",
    "            x[:,cont:cont_end] = mc[:,burnin+1:,i]\n",
    "            y_s[cont:cont_end] = y[burnin+1:]\n",
    "            cont = cont + int(1/p)\n",
    "        y = y_s\n",
    "        nf = len(y[y<0])\n",
    "    prob = p**(L-1) * nf/N\n",
    "    pf.append(prob)\n",
    "    # pf[count] = p**(L-1) *nf[L]/N\n",
    "pf = np.array(pf)\n",
    "avgg = np.mean(pf)\n",
    "covv = np.std(pf)/np.mean(pf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023487700000000005"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn_trials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
